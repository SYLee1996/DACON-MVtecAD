{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 18 02:08:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.54       Driver Version: 510.54       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000     Off  | 00000000:3B:00.0 Off |                  Off |\n",
      "| 33%   29C    P0    48W / 230W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 5000     Off  | 00000000:5E:00.0 Off |                  Off |\n",
      "| 32%   31C    P0    39W / 230W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 5000     Off  | 00000000:AF:00.0 Off |                  Off |\n",
      "| 32%   32C    P0    40W / 230W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 5000     Off  | 00000000:D8:00.0 Off |                  Off |\n",
      "| 32%   32C    P0    32W / 230W |      0MiB / 16384MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Augmentation      \n",
    "    + 기본적으로 Albumentation 사용\n",
    "    + Sobel filter를 이용한 증강을 추가(다른 filter 및 LBP 등등 사용해봤는데, Sobel filter가 가장 성능이 잘 나왔습니다)      \n",
    "    + Train, Test 시에도 augmentation 수행      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train     \n",
    "    + CosineAnnealingWarmUpRestarts - Scheduler(warmup을 하지 않고 학습)      \n",
    "    + LabelSmoothing_with_CrossEntropy - Loss  \n",
    "    + AdamW - optimizer\n",
    "    + amp.GradScaler        \n",
    "    + EarlyStopping(Loss, Acc 동시에 적용 |, & 대신 -> and, or 사용)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model     \n",
    "    + EfficientNet_b7 사용\n",
    "    + 5-fold 진행\n",
    "    + Public 기준 상위 2개 모델 blending      \n",
    "        -> EfficientNet_b7 (Public-LB: 0.89066, LR: 2e-4)       \n",
    "        -> EfficientNet_b7 (Public-LB: 0.88658, LR: 1.5e-4)     \n",
    "    + TTA\n",
    "        -> tta.HorizontalFlip()     \n",
    "        -> tta.VerticalFlip()       \n",
    "        -> tta.Rotate90(angles=[0, 90, 180, 270])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU activate --> Count of using GPUs: 4\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ttach as tta \n",
    "import albumentations\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "# Hyperparameter definition\n",
    "seed = 10\n",
    "suffix = (datetime.datetime.now() + datetime.timedelta(hours=9)).strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "config = {\n",
    "    # Model parameters\n",
    "    'model': 'efficientnet_b7',\n",
    "    'batch_size': 32,\n",
    "    'pretrain': True,\n",
    "    \n",
    "    # Optimizer parameters\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr': 2e-4,\n",
    "    'lr_t': 15,\n",
    "    'lr_scheduler': 'CosineAnnealingWarmUpRestarts',\n",
    "    'gamma': 0.524,\n",
    "    'loss_function': 'CE_with_Lb',\n",
    "    'patience': 10,\n",
    "    'weight_decay': 0.002157,\n",
    "    'label_smoothing': 0.8283,\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 200,\n",
    "    'n_fold': 5,\n",
    "    'num_workers': 16,\n",
    "    'text': \"A\",\n",
    "    'device': '0,1,2,3'\n",
    "    }\n",
    "\n",
    "\n",
    "model_save_name='./RESULTS/'+config['text']+\"_\"+suffix+\"(\"+ str(config['model'])+\"_\"+\\\n",
    "                                                            str(config['batch_size'])+\"_\"+\\\n",
    "                                                            str(config['pretrain'])+\"__\"+\\\n",
    "                                                            str(config['optimizer'])+\"_\"+\\\n",
    "                                                            str(config['lr'])+\"_\"+\\\n",
    "                                                            str(config['lr_t'])+\"_\"+\\\n",
    "                                                            str(config['lr_scheduler'])+\"_\"+\\\n",
    "                                                            str(config['gamma'])+\"_\"+\\\n",
    "                                                            str(config['loss_function'])+\"_\"+\\\n",
    "                                                            str(config['patience'])+\"_\"+\\\n",
    "                                                            str(config['weight_decay'])+\"_\"+\\\n",
    "                                                            str(config['label_smoothing'])+\")_fold_\"\n",
    "                                                        \n",
    "config['model_save_name'] = model_save_name\n",
    "# -------------------------------------------------------------------------------------------\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config['device']\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "print('Device: %s' % device)\n",
    "if (device.type == 'cuda') or (torch.cuda.device_count() > 1):\n",
    "    print('GPU activate --> Count of using GPUs: %s' % torch.cuda.device_count())\n",
    "config['device'] = device\n",
    "\n",
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Augmentation 시 albumentation을 사용하였으며, 추가적으로 Sobel filter를 이용하여 edge를 추출 후 unsharp image와 합친 Augmentation을 만들어 사용\n",
    "\n",
    "* train 시 Sharpen, HueSaturationValue, FancyPCA, Emboss의 augmentation을 통해 이미지를 선명하게 만든 후 다른 aumgmentation을 수행\n",
    "\n",
    "* test 시에는 Sharpen, HueSaturationValue, FancyPCA, Emboss의 augmentation만 수행            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        img = cv2.resize(img, (512, 512))\n",
    "        return img\n",
    "\n",
    "\n",
    "def score_function(real, pred):\n",
    "        score = f1_score(real, pred, average=\"macro\")\n",
    "        return score\n",
    "\n",
    "\n",
    "class Magnitude_Sobel32f_Unsharp_compose(ImageOnlyTransform):\n",
    "    def __init__(self, dx=1, dy=0, ksize=3, blur_limit=(1,5), sigmaX=2.0, always_apply=False, p=0.5):\n",
    "        super(Magnitude_Sobel32f_Unsharp_compose, self).__init__(always_apply=always_apply, p=p)\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "        self.ksize = ksize\n",
    "        self.blur_limit = blur_limit\n",
    "        self.sigmaX = sigmaX\n",
    "        \n",
    "    def apply(self, img, **params):        \n",
    "        sobelx32f_x = cv2.Sobel(img, cv2.CV_32F, self.dx, self.dy, ksize=self.ksize)\n",
    "        sobelx32f_y = cv2.Sobel(img, cv2.CV_32F, self.dy, self.dx, ksize=self.ksize)\n",
    "        sobel32f = cv2.magnitude(sobelx32f_x, sobelx32f_y) \n",
    "        sobel32f = np.clip(sobel32f, 0, 255).astype(np.uint8) \n",
    "                \n",
    "        gaussian = cv2.GaussianBlur(img, self.blur_limit, self.sigmaX)\n",
    "        unsharp_image = cv2.addWeighted(img, self.sigmaX, gaussian, -1.0, 0)\n",
    "        \n",
    "        return  cv2.add(unsharp_image, sobel32f)\n",
    "\n",
    "\n",
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.augmentation = albumentations.Compose([\n",
    "            albumentations.Sharpen(p=0.7),\n",
    "            albumentations.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=0.3),\n",
    "            albumentations.FancyPCA(alpha=0.1, p=0.3),\n",
    "            albumentations.Emboss(p=0.5),\n",
    "            Magnitude_Sobel32f_Unsharp_compose(dx=1, dy=0, ksize=1, blur_limit=(1,5), sigmaX=2.0, p=0.3),\n",
    "            \n",
    "            albumentations.Transpose(p=0.3),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.RandomRotate90(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "\n",
    "            albumentations.CLAHE(clip_limit=5, p=0.4),\n",
    "            albumentations.ElasticTransform(alpha_affine=30, p=0.4), \n",
    "            albumentations.Posterize(p=0.5),\n",
    "\n",
    "            albumentations.GaussNoise(p=0.3),\n",
    "            albumentations.GaussianBlur(blur_limit=(1, 5), p=0.3),\n",
    "            albumentations.GlassBlur(sigma=0.1, max_delta=2, iterations=1, p=0.2),  \n",
    "            albumentations.GridDistortion(num_steps=20, distort_limit=0.3, border_mode=1, p=0.2), \n",
    "            ])\n",
    "        \n",
    "        self.test_augmentation = albumentations.Compose([\n",
    "            albumentations.Sharpen(p=0.7),\n",
    "            albumentations.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=0.3),\n",
    "            albumentations.FancyPCA(alpha=0.1, p=0.3),\n",
    "            albumentations.Emboss(p=0.5),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        raw_img = copy.deepcopy(img)\n",
    "        \n",
    "        if self.mode=='train':\n",
    "            augmented = self.augmentation(image=img) \n",
    "            img = augmented['image']\n",
    "        else:\n",
    "            augmented = self.test_augmentation(image=img) \n",
    "            img = augmented['image']\n",
    "            \n",
    "        img = transforms.ToTensor()(img)\n",
    "        raw_img = transforms.ToTensor()(raw_img)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {'img' : img,\n",
    "                'raw_img' : raw_img, \n",
    "                'label' : label}\n",
    "\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth_one_hot(targets:torch.Tensor, n_classes:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = torch.empty(size=(targets.size(0), n_classes),\n",
    "                    device=targets.device) \\\n",
    "                .fill_(smoothing /(n_classes-1)) \\\n",
    "                .scatter_(1, targets.data.unsqueeze(1), 1.-smoothing)\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        lsm = F.log_softmax(inputs, -1)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            lsm = lsm * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = -(targets * lsm).sum(-1)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if torch.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = config['model']\n",
    "        self.class_num = config['class_num']\n",
    "        self.pretrain = config['pretrain']\n",
    "\n",
    "        if self.model == 'efficientnet_b7':\n",
    "            self.model =  EfficientNet.from_pretrained('efficientnet-b7', num_classes=self.class_num)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [01:39<00:00, 42.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataload\n",
    "train_png = sorted(glob('./open/train/*.png'))    \n",
    "train_y = pd.read_csv(\"./open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "config['class_num'] = len(label_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(train_imgs, train_labels, config):\n",
    "    \n",
    "    print('model_save_name: '+config['model_save_name'].split(\"/\")[-1])\n",
    "    # Cross Validation\n",
    "    kfold = StratifiedKFold(n_splits=config['n_fold'],shuffle=True,random_state=seed)\n",
    "    n_fold = config['n_fold']\n",
    "    k_train_f1, k_valid_f1 = [], []   \n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kfold.split(train_imgs,train_labels)):\n",
    "\n",
    "        Train_set = [train_imgs[i] for i in train_idx]\n",
    "        Valid_set = [train_imgs[i] for i in valid_idx]\n",
    "        Train_label_set = [train_labels[i] for i in train_idx]\n",
    "        Valid_label_set = [train_labels[i] for i in valid_idx]\n",
    "\n",
    "        # Train\n",
    "        Train_dataset = Custom_dataset(np.array(Train_set), np.array(Train_label_set), mode='train')\n",
    "        Train_loader = DataLoader(Train_dataset, batch_size=config['batch_size'], pin_memory=True,\n",
    "                                num_workers=config['num_workers'], prefetch_factor=config['batch_size']*2, \n",
    "                                shuffle=True)\n",
    "\n",
    "        # Valid\n",
    "        Valid_dataset = Custom_dataset(np.array(Valid_set), np.array(Valid_label_set), mode='test')\n",
    "        Valid_loader = DataLoader(Valid_dataset, batch_size=config['batch_size'], pin_memory=True,\n",
    "                                num_workers=config['num_workers'], prefetch_factor=config['batch_size']*2, \n",
    "                                shuffle=True)\n",
    "        \n",
    "        model = Network(config).to(config['device'])\n",
    "        model = nn.DataParallel(model).to(config['device'])\n",
    "\n",
    "        if config['lr_scheduler'] == 'CosineAnnealingLR':\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['lr_t'], eta_min=0)\n",
    "            \n",
    "        elif config['lr_scheduler'] == 'CosineAnnealingWarmUpRestarts':\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=0, weight_decay=config['weight_decay'])\n",
    "            scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=config['lr_t'], eta_max=config['lr'], gamma=config['gamma'], T_mult=1, T_up=0)\n",
    "        \n",
    "        criterion = SmoothCrossEntropyLoss(smoothing=config['label_smoothing']).to(config['device'])\n",
    "        scaler = torch.cuda.amp.GradScaler() \n",
    "        early_stopping = EarlyStopping(patience=config['patience'], mode='max')\n",
    "        early_stopping_loss = EarlyStopping(patience=config['patience'], mode='min')\n",
    "        \n",
    "        best=0.5\n",
    "        best_loss=100\n",
    "        each_fold_train_loss, each_fold_train_f1 = [], []\n",
    "        each_fold_valid_loss, each_fold_valid_f1 = [], []\n",
    "        epochs = config['epochs']\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_pred, train_real = 0, [], []\n",
    "            valid_loss, valid_pred, valid_real = 0, [], []\n",
    "\n",
    "            model.train()\n",
    "            for batch_id, batch in tqdm(enumerate(Train_loader), total=len(Train_loader)):\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                x = torch.tensor(batch['img'], dtype=torch.float32).to(config['device'])\n",
    "                y = torch.tensor(batch['label'], dtype=torch.long).to(config['device'])\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "                train_real += y.detach().cpu().numpy().tolist()\n",
    "            train_loss = train_loss/len(Train_loader)\n",
    "            train_f1 = score_function(train_real, train_pred)\n",
    "            each_fold_train_loss.append(train_loss)\n",
    "            each_fold_train_f1.append(train_f1)\n",
    "            scheduler.step()\n",
    "        \n",
    "            model.eval()\n",
    "            for batch_id, val_batch in tqdm(enumerate(Valid_loader), total=len(Valid_loader)):\n",
    "                with torch.no_grad():\n",
    "                    val_x = torch.tensor(val_batch['img'], dtype=torch.float32).to(config['device'])\n",
    "                    val_y = torch.tensor(val_batch['label'], dtype=torch.long).to(config['device'])\n",
    "\n",
    "                    val_pred = model(val_x)\n",
    "                    val_loss = criterion(val_pred, val_y)\n",
    "\n",
    "                valid_loss += val_loss.item()\n",
    "                valid_pred += val_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "                valid_real += val_y.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            valid_loss = valid_loss/len(Valid_loader)\n",
    "            valid_f1 = score_function(valid_real, valid_pred)\n",
    "            each_fold_valid_loss.append(valid_loss)\n",
    "            each_fold_valid_f1.append(valid_f1)\n",
    "            \n",
    "            print_best = 0    \n",
    "            if (each_fold_valid_f1[-1] >= best) or (each_fold_valid_loss[-1] <= best_loss):\n",
    "                difference = each_fold_valid_f1[-1] - best\n",
    "                if (each_fold_valid_f1[-1] >= best):\n",
    "                    best = each_fold_valid_f1[-1] \n",
    "                if (each_fold_valid_loss[-1] <= best_loss):\n",
    "                    best_loss = each_fold_valid_loss[-1]\n",
    "                \n",
    "                pprint_best = each_fold_valid_f1[-1]\n",
    "                pprint_best_loss = each_fold_valid_loss[-1]\n",
    "                \n",
    "                best_idx = epoch+1\n",
    "                model_state_dict = model.module.state_dict() if torch.cuda.device_count() > 1 else model.module.state_dict()\n",
    "                best_model_wts = copy.deepcopy(model_state_dict)\n",
    "                \n",
    "                # load and save best model weights\n",
    "                model.module.load_state_dict(best_model_wts)\n",
    "                torch.save(best_model_wts, config['model_save_name'] + str(fold+1) + \".pt\")\n",
    "                print_best = '==> best model saved %d epoch / acc: %.5f  loss: %.5f  /  difference %.5f'%(best_idx, pprint_best, pprint_best_loss, difference)\n",
    "\n",
    "            print(f'Fold : {fold+1}/{n_fold}    epoch : {epoch+1}/{epochs}')\n",
    "            print(f'TRAIN_Loss : {train_loss:.5f}    TRAIN_F1 : {train_f1:.5f}')\n",
    "            print(f'VALID_Loss : {valid_loss:.5f}    VALID_F1 : {valid_f1:.5f}    BEST : {pprint_best:.5f}    BEST_LOSS : {pprint_best_loss:.5f}')\n",
    "            print('\\n') if type(print_best)==int else print(print_best,'\\n')\n",
    "\n",
    "            if early_stopping.step(torch.tensor(each_fold_valid_f1[-1])) and early_stopping_loss.step(torch.tensor(each_fold_valid_loss[-1])):\n",
    "                break\n",
    "            \n",
    "        print(\"VALID Loss: \", pprint_best_loss, \", VALID F1: \", pprint_best)\n",
    "            \n",
    "        k_train_f1.append(pprint_best_loss)\n",
    "        k_valid_f1.append(pprint_best)\n",
    "        \n",
    "    print(config['model_save_name'].split(\"/\")[-1] + ' is saved!')\n",
    "\n",
    "    print(\"1Fold - VALID Loss: \", k_train_f1[0], \", 1Fold - VALID F1: \", k_valid_f1[0])\n",
    "    print(\"2Fold - VALID Loss: \", k_train_f1[1], \", 2Fold - VALID F1: \", k_valid_f1[1])\n",
    "    print(\"3Fold - VALID Loss: \", k_train_f1[2], \", 3Fold - VALID F1: \", k_valid_f1[2])\n",
    "    print(\"4Fold - VALID Loss: \", k_train_f1[3], \", 4Fold - VALID F1: \", k_valid_f1[3])\n",
    "    print(\"5Fold - VALID Loss: \", k_train_f1[4], \", 5Fold - VALID F1: \", k_valid_f1[4])\n",
    "\n",
    "    print(\"k-fold Valid Loss: \",np.mean(k_train_f1),\", k-fold Valid F1: \",np.mean(k_valid_f1))\n",
    "    \n",
    "    return config['model_save_name'].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_1 = train_func(train_imgs, train_labels, config)\n",
    "\n",
    "# Blending을 하려면 아래 코드 또한 돌려야합니다.\n",
    "# config['lr'] = 1.5e-4\n",
    "# model_path_2 = train_func(train_imgs, train_labels, config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['model_save_list'] = [model_path_1] # Blending X\n",
    "# config['model_save_list'] = [model_path_1, model_path_2] # Blending O\n",
    "config['save_name'] = 'INFERNECE_SAMPLE'\n",
    "\n",
    "\n",
    "# Dataload\n",
    "test_png = sorted(glob('/data/open/test/*.png'))\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]\n",
    "\n",
    "# Test\n",
    "Test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "Test_loader = DataLoader(Test_dataset, batch_size=config['batch_size'], pin_memory=True,\n",
    "                        num_workers=config['num_workers'], prefetch_factor=config['batch_size']*2, \n",
    "                        shuffle=False)\n",
    "\n",
    "transforms = tta.Compose([\n",
    "    tta.HorizontalFlip(),\n",
    "    tta.VerticalFlip(),\n",
    "    tta.Rotate90(angles=[0, 90, 180, 270]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "tta_models = []\n",
    "\n",
    "for model_name in config['model_save_list']:\n",
    "    for fold in range(config['n_fold']):\n",
    "    \n",
    "        model_dict = torch.load('./RESULTS/'+model_name + str(fold+1) + \".pt\")\n",
    "        model = Network(config).to(config['device']) \n",
    "        model = nn.DataParallel(model).to(config['device'])\n",
    "        model.module.load_state_dict(model_dict) if torch.cuda.device_count() > 1 else model.load_state_dict(model_dict)\n",
    "        \n",
    "        tta_model = tta.ClassificationTTAWrapper(model, transforms, merge_mode='sum').to(config['device'])\n",
    "        models.append(model)\n",
    "        tta_models.append(tta_model)\n",
    "\n",
    "results = []\n",
    "for batch_id, batch in tqdm(enumerate(Test_loader), total=len(Test_loader)):\n",
    "    x = torch.tensor(batch['img'], dtype = torch.float32, device = device)\n",
    "    raw_x = torch.tensor(batch['raw_img'], dtype = torch.float32, device = device)\n",
    "    \n",
    "    for fold, (model, tta_model) in enumerate(zip(models, tta_models)):\n",
    "        model.eval()\n",
    "        tta_model.eval() \n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                if fold == 0:\n",
    "                    output = model(x)+tta_model(batch['raw_img'])\n",
    "                else:\n",
    "                    output = output+model(x)+tta_model(batch['raw_img'])\n",
    "\n",
    "    output = len(models)*output\n",
    "    output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n",
    "    results.extend(output)\n",
    "\n",
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "results = [label_decoder[result] for result in results]\n",
    "submission = pd.read_csv(\"./open/sample_submission.csv\")\n",
    "submission[\"label\"] = results\n",
    "\n",
    "submission.to_csv(\"./RESULTS/{}.csv\".format(config['save_name']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
